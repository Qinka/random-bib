@Article{art/LiJ_202311,
  author        = {Li, Johann and Zhu, Guangming and Hua, Cong and Feng, Mingtao and Bennamoun, Basheer and Li, Ping and Lu, Xiaoyuan and Song, Juan and Shen, Peiyi and Xu, Xu and Mei, Lin and Zhang, Liang and Shah, Syed Afaq Ali and Bennamoun, Mohammed},
  journal       = {ACM Computing Surveys},
  title         = {A Systematic Collection of Medical Image Datasets for Deep Learning},
  year          = {2023},
  issn          = {1557-7341},
  month         = nov,
  number        = {5},
  pages         = {1--51},
  volume        = {56},
  abstract      = {The astounding success made by artificial intelligence (AI) in healthcare and other fields proves that AI can achieve human-like performance. However, success always comes with challenges. Deep learning algorithms are data-dependent and require large datasets for training. The lack of data in the medical imaging field creates a bottleneck for the application of deep learning to medical image analysis. Medical image acquisition, annotation, and analysis are costly, and their usage is constrained by ethical restrictions. They also require many resources, such as human expertise and funding. That makes it difficult for non-medical researchers to have access to useful and large medical data. Thus, as comprehensive as possible, this paper provides a collection of medical image datasets with their associated challenges for deep learning research. We have collected information of around three hundred datasets and challenges mainly reported between 2013 and 2020 and categorized them into four categories: head & neck, chest & abdomen, pathology & blood, and ``others''. Our paper has three purposes: 1) to provide a most up to date and complete list that can be used as a universal reference to easily find the datasets for clinical image analysis, 2) to guide researchers on the methodology to test and evaluate their methods' performance and robustness on relevant datasets, 3) to provide a ``route'' to relevant algorithms for the relevant medical topics, and challenge leaderboards.},
  archiveprefix = {arXiv},
  arxivid       = {2106.12864},
  doi           = {10.1145/3615862},
  eprint        = {2106.12864},
  groups        = {Own},
  publisher     = {Association for Computing Machinery (ACM)},
  url           = {http://arxiv.org/abs/2106.12864},
}

@Article{art/FanZ_202104,
  author    = {Fan, Zhonghao and Li, Johann and Zhang, Liang and Zhu, Guangming and Li, Ping and Lu, Xiaoyuan and Shen, Peiyi and Shah, Syed Afaq Ali and Bennamoun, Mohammed and Hua, Tao and Wei, Wei},
  journal   = {Neural Computing and Applications},
  title     = {U-net based analysis of MRI for Alzheimer’s disease diagnosis},
  year      = {2021},
  issn      = {1433-3058},
  month     = apr,
  number    = {20},
  pages     = {13587--13599},
  volume    = {33},
  abstract  = {Alzheimer's disease (AD) is the most common type of dementia that still has no effective treatment. Accurate classification of AD can help in its diagnosis and selection of the most effective treatment options. In the last decade, several studies have proven the effectiveness of deep learning algorithms for AD diagnosis. In this paper, we propose a U-net style model for AD diagnosis using 3D T1-weighted magnetic resonance images (MRI). Combining with deep supervision has been proved to be effective in improving the performance of the model. Our method has been tested on a subset of ADNI dataset and AIBL dataset and achieves a superior average accuracy of 95.71 ± 1.36 % for AD versus NC (normal control), 90.14 ± 3.66 % for EMCI (early mild cognitive impairment) versus LMCI (late mild cognitive impairment), 90.05 ± 2.63 % for AD versus LMCI, and 87.98 ± 4.54 % for NC versus EMCI, respectively. Besides these binary-classification tasks, we also test this model for multi-class classification task (AD vs. NC vs. EMCI vs. LMCI) and it achieves an accuracy of 86.47 ± 9.60 %. Furthermore, 3D-Grad-CAM method is used to visualize the focused areas of the proposed model. We find that the proposed model pays more attention to the characteristics of the ventricles, hippocampus, and some regions of cortex, which have been proven to be affected by AD.},
  doi       = {10.1007/s00521-021-05983-y},
  groups    = {Own},
  keywords  = {Alzheimer's disease,Deep supervision,Diagnosis,Multi-tasks,U-net,Visualization},
  publisher = {Springer Science and Business Media LLC},
  url       = {https://link.springer.com/10.1007/s00521-021-05983-y},
}

@Article{art/LiP_202102,
  author    = {Li, Ping and Kong, Xiangwen and Li, Johann and Zhu, Guangming and Lu, Xiaoyuan and Shen, Peiyi and Shah, Syed Afaq Ali and Bennamoun, Mohammed and Hua, Tao},
  journal   = {Frontiers in Digital Health},
  title     = {A Dataset of Pulmonary Lesions With Multiple-Level Attributes and Fine Contours},
  year      = {2021},
  issn      = {2673-253X},
  month     = feb,
  volume    = {2},
  abstract  = {Lung cancer is a life-threatening disease and its diagnosis is of great significance. Data scarcity and unavailability of datasets is a major bottleneck in lung cancer research. In this paper, we introduce a dataset of pulmonary lesions for designing the computer-aided diagnosis (CAD) systems. The dataset has fine contour annotations and nine attribute annotations. We define the structure of the dataset in detail, and then discuss the relationship of the attributes and pathology, and the correlation between the nine attributes with the chi-square test. To demonstrate the contribution of our dataset to computer-aided system design, we define four tasks that can be developed using our dataset. Then, we use our dataset to model multi-attribute classification tasks. We discuss the performance in 2D, 2.5D, and 3D input modes of the classification model. To improve performance, we introduce two attention mechanisms and verify the principles of the attention mechanisms through visualization. Experimental results show the relationship between different models and different levels of attributes.},
  doi       = {10.3389/fdgth.2020.609349},
  groups    = {Own},
  publisher = {Frontiers Media SA},
  url       = {https://www.frontiersin.org/articles/10.3389/fdgth.2020.609349/full},
}

@Article{art/ZhangL_202201,
  author        = {Zhang, Liang and Li, Johann and Li, Ping and Lu, Xiaoyuan and Gong, Maoguo and Shen, Peiyi and Zhu, Guangming and Shah, Syed Afaq and Bennamoun, Mohammed and Qian, Kun and Schuller, Björn W.},
  journal       = {Neural Computing and Applications},
  title         = {MEDAS: an open-source platform as a service to help break the walls between medicine and informatics},
  year          = {2022},
  issn          = {1433-3058},
  month         = jan,
  number        = {8},
  pages         = {6547--6567},
  volume        = {34},
  abstract      = {In the past decade, deep learning (DL) has achieved unprecedented success in numerous fields including computer vision, natural language processing, and healthcare. In particular, DL is experiencing an increasing development in applications for advanced medical image analysis in terms of analysis, segmentation, classification, and furthermore. On the one hand, tremendous needs that leverage the power of DL for medical image analysis are arising from the research community of a medical, clinical, and informatics background to jointly share their expertise, knowledge, skills, and experience. On the other hand, barriers between disciplines are on the road for them often hampering a full and efficient collaboration. To this end, we propose our novel open-source platform, i.e., MeDaS -- the MeDical open-source platform as Service. To the best of our knowledge, MeDaS is the first open-source platform proving a collaborative and interactive service for researchers from a medical background easily using DL related toolkits, and at the same time for scientists or engineers from information sciences to understand the medical knowledge side. Based on a series of toolkits and utilities from the idea of RINV (Rapid Implementation aNd Verification), our proposed MeDaS platform can implement pre-processing, post-processing, augmentation, visualization, and other phases needed in medical image analysis. Five tasks including the subjects of lung, liver, brain, chest, and pathology, are validated and demonstrated to be efficiently realisable by using MeDaS.},
  archiveprefix = {arXiv},
  arxivid       = {2007.06013},
  doi           = {10.1007/s00521-021-06750-9},
  eprint        = {2007.06013},
  groups        = {Own},
  publisher     = {Springer Science and Business Media LLC},
  url           = {http://arxiv.org/abs/2007.06013},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: keypatterndefault:art/[auth][authForeIni:upper]_[date:regex("-".""):truncate6];}
