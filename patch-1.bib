
@Article{s21237786,
AUTHOR = {Pandya, Sharnil and Thakur, Aanchal and Saxena, Santosh and Jassal, Nandita and Patel, Chirag and Modi, Kirit and Shah, Pooja and Joshi, Rahul and Gonge, Sudhanshu and Kadam, Kalyani and Kadam, Prachi},
TITLE = {A Study of the Recent Trends of Immunology: Key Challenges, Domains, Applications, Datasets, and Future Directions},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {7786},
URL = {https://www.mdpi.com/1424-8220/21/23/7786},
PubMedID = {34883787},
ISSN = {1424-8220},
ABSTRACT = {The human immune system is very complex. Understanding it traditionally required specialized knowledge and expertise along with years of study. However, in recent times, the introduction of technologies such as AIoMT (Artificial Intelligence of Medical Things), genetic intelligence algorithms, smart immunological methodologies, etc., has made this process easier. These technologies can observe relations and patterns that humans do and recognize patterns that are unobservable by humans. Furthermore, these technologies have also enabled us to understand better the different types of cells in the immune system, their structures, their importance, and their impact on our immunity, particularly in the case of debilitating diseases such as cancer. The undertaken study explores the AI methodologies currently in the field of immunology. The initial part of this study explains the integration of AI in healthcare and how it has changed the face of the medical industry. It also details the current applications of AI in the different healthcare domains and the key challenges faced when trying to integrate AI with healthcare, along with the recent developments and contributions in this field by other researchers. The core part of this study is focused on exploring the most common classifications of health diseases, immunology, and its key subdomains. The later part of the study presents a statistical analysis of the contributions in AI in the different domains of immunology and an in-depth review of the machine learning and deep learning methodologies and algorithms that can and have been applied in the field of immunology. We have also analyzed a list of machine learning and deep learning datasets about the different subdomains of immunology. Finally, in the end, the presented study discusses the future research directions in the field of AI in immunology and provides some possible solutions for the same.},
DOI = {10.3390/s21237786}
}
@article{PATEL2018284,
title = {Human action recognition using fusion of features for unconstrained video sequences},
journal = {Computers \& Electrical Engineering},
volume = {70},
pages = {284-301},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2016.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0045790616301598},
author = {Chirag I Patel and Sanjay Garg and Tanish Zaveri and Asim Banerjee and Ripal Patel},
keywords = {Human action recognition, Histogram of oriented gradient (HOG), Local binary pattern (LBP), Artificial neural network, Support vector machine, Multiple kernel learning, Decision combination neural network (DCNN), Choquet’s fuzzy integral (CFI), Decison template},
abstract = {Effective modeling of the human action using different features is a critical task for human action recognition; hence, the fusion of features concept has been used in our proposed work. By fusing several modalities, features, or classifier decision scores, we present six different fusion models inspired by the early fusion schemes, late fusion schemes, and intermediate fusion schemes. In the first two models, we have utilized early fusion technique. The third and fourth models exploit intermediate fusion techniques. In the fourth model, we confront a kernel-based fusion scheme, which takes advantage of kernel basis of classifiers i.e. Support Vector Machine (SVM). In the fifth and sixth models, we have demonstrated late fusion techniques. The performance of all models is evaluated with ASLAN and UCF11 benchmark dataset of action videos. We obtained significant improvements with the proposed fusion schemes relative to the usual fusion schemes relative state-of-the-art methods.}
}
@misc{zhuang2020comprehensive,
      title={A Comprehensive Survey on Transfer Learning},
      author={Fuzhen Zhuang and Zhiyuan Qi and Keyu Duan and Dongbo Xi and Yongchun Zhu and Hengshu Zhu and Hui Xiong and Qing He},
      year={2020},
      eprint={1911.02685},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{KARIMI2021102078,
title = {Transfer learning in medical image segmentation: New insights from analysis of the dynamics of model parameters and learned representations},
journal = {Artificial Intelligence in Medicine},
volume = {116},
pages = {102078},
year = {2021},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2021.102078},
url = {https://www.sciencedirect.com/science/article/pii/S0933365721000713},
author = {Davood Karimi and Simon K. Warfield and Ali Gholipour},
keywords = {Medical image segmentation, Fully convolutional neural networks, Deep learning, Transfer learning},
abstract = {We present a critical assessment of the role of transfer learning in training fully convolutional networks (FCNs) for medical image segmentation. We first show that although transfer learning reduces the training time on the target task, improvements in segmentation accuracy are highly task/data-dependent. Large improvements are observed only when the segmentation task is more challenging and the target training data is smaller. We shed light on these observations by investigating the impact of transfer learning on the evolution of model parameters and learned representations. We observe that convolutional filters change little during training and still look random at convergence. We further show that quite accurate FCNs can be built by freezing the encoder section of the network at random values and only training the decoder section. At least for medical image segmentation, this finding challenges the common belief that the encoder section needs to learn data/task-specific representations. We examine the evolution of FCN representations to gain a deeper insight into the effects of transfer learning on the training dynamics. Our analysis shows that although FCNs trained via transfer learning learn different representations than FCNs trained with random initialization, the variability among FCNs trained via transfer learning can be as high as that among FCNs trained with random initialization. Moreover, feature reuse is not restricted to the early encoder layers; rather, it can be more significant in deeper layers. These findings offer new insights and suggest alternative ways of training FCNs for medical image segmentation.}
}
@Article{Kim2022,
author="Kim, Hee E.
and Cosa-Linan, Alejandro
and Santhanam, Nandhini
and Jannesari, Mahboubeh
and Maros, Mate E.
and Ganslandt, Thomas",
title="Transfer learning for medical image classification: a literature review",
journal="BMC Medical Imaging",
year="2022",
month="Apr",
day="13",
volume="22",
number="1",
pages="69",
abstract="Transfer learning (TL) with convolutional neural networks aims to improve performances on a new task by leveraging the knowledge of similar tasks learned in advance. It has made a major contribution to medical image analysis as it overcomes the data scarcity problem as well as it saves time and hardware resources. However, transfer learning has been arbitrarily configured in the majority of studies. This review paper attempts to provide guidance for selecting a model and TL approaches for the medical image classification task.",
issn="1471-2342",
doi="10.1186/s12880-022-00793-7",
url="https://doi.org/10.1186/s12880-022-00793-7"
}

@article{EGGER2022106874,
title = {Medical deep learning—A systematic meta-review},
journal = {Computer Methods and Programs in Biomedicine},
volume = {221},
pages = {106874},
year = {2022},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2022.106874},
url = {https://www.sciencedirect.com/science/article/pii/S0169260722002565},
author = {Jan Egger and Christina Gsaxner and Antonio Pepe and Kelsey L. Pomykala and Frederic Jonske and Manuel Kurz and Jianning Li and Jens Kleesiek},
keywords = {Deep learning, Artificial neural networks, Machine learning, Data analysis, Image analysis, Medical image analysis, Medical image processing, Medical imaging, Patient data, Pathology, Detection, Segmentation, Registration, Generative adversarial networks, PubMed, Systematic, Review, Survey, Meta-review, Meta-survey},
abstract = {Deep learning has remarkably impacted several different scientific disciplines over the last few years. For example, in image processing and analysis, deep learning algorithms were able to outperform other cutting-edge methods. Additionally, deep learning has delivered state-of-the-art results in tasks like autonomous driving, outclassing previous attempts. There are even instances where deep learning outperformed humans, for example with object recognition and gaming. Deep learning is also showing vast potential in the medical domain. With the collection of large quantities of patient records and data, and a trend towards personalized treatments, there is a great need for automated and reliable processing and analysis of health information. Patient data is not only collected in clinical centers, like hospitals and private practices, but also by mobile healthcare apps or online websites. The abundance of collected patient data and the recent growth in the deep learning field has resulted in a large increase in research efforts. In Q2/2020, the search engine PubMed returned already over 11,000 results for the search term ‘deep learning’, and around 90\% of these publications are from the last three years. However, even though PubMed represents the largest search engine in the medical field, it does not cover all medical-related publications. Hence, a complete overview of the field of ‘medical deep learning’ is almost impossible to obtain and acquiring a full overview of medical sub-fields is becoming increasingly more difficult. Nevertheless, several review and survey articles about medical deep learning have been published within the last few years. They focus, in general, on specific medical scenarios, like the analysis of medical images containing specific pathologies. With these surveys as a foundation, the aim of this article is to provide the first high-level, systematic meta-review of medical deep learning surveys.}
}
@article{LAAL201360,
title = {Innovation Process in Medical Imaging},
journal = {Procedia - Social and Behavioral Sciences},
volume = {81},
pages = {60-64},
year = {2013},
note = {World Congress on Administrative and Political Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.06.388},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813014559},
author = {Marjan Laal},
keywords = {Medical Imaging, Innovation Process, Improvement, Progress},
abstract = {This article reviews improving process in medical imaging thanks to innovation and technology. Medical imaging is the technique and process used to create images of human body for clinical purposes or medical science. Since Wilhelm Roentgen's discovery of X-rays in 1895, medical imaging has undergone near continuous innovation. After the Second World War, multiple generations of innovations and new discoveries, focused on the interaction of computerization and imaging technologies, took place in X-ray, computed tomography, magnetic resonance imaging, nuclear imaging, and ultrasound-positioned medical imaging, led to transforming healthcare science. Medical imaging has brought a high sense of vision into medical science, leading to an extensive change in healthcare system.}
}
@InProceedings{10.1007/978-3-642-16444-6_63,
author="Ganguly, Debashis
and Chakraborty, Srabonti
and Balitanas, Maricel
and Kim, Tai-hoon",
editor="Kim, Tai-hoon
and Stoica, Adrian
and Chang, Ruay-Shiung",
title="Medical Imaging: A Review",
booktitle="Security-Enriched Urban Computing and Smart Grid",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="504--516",
abstract="The rapid progress of medical science and the invention of various medicines have benefited mankind and the whole civilization. Modern science also has been doing wonders in the surgical field. But, the proper and correct diagnosis of diseases is the primary necessity before the treatment. The more sophisticate the bio-instruments are, better diagnosis will be possible. The medical images plays an important role in clinical diagnosis and therapy of doctor and teaching and researching etc. Medical imaging is often thought of as a way to represent anatomical structures of the body with the help of X-ray computed tomography and magnetic resonance imaging. But often it is more useful for physiologic function rather than anatomy. With the growth of computer and image technology medical imaging has greatly influenced medical field. As the quality of medical imaging affects diagnosis the medical image processing has become a hotspot and the clinical applications wanting to store and retrieve images for future purpose needs some convenient process to store those images in details. This paper is a tutorial review of the medical image processing and repository techniques appeared in the literature.",
isbn="978-3-642-16444-6"
}
@article{Bercovich2018,
  doi = {10.5041/rmmj.10355},
  url = {https://doi.org/10.5041/rmmj.10355},
  year = {2018},
  month = oct,
  publisher = {Rambam Health Corporation},
  volume = {9},
  number = {4},
  pages = {e0034},
  author = {Eyal Bercovich and Marcia C. Javitt},
  title = {Medical Imaging: From Roentgen to the Digital Revolution,  and Beyond},
  journal = {Rambam Maimonides Medical Journal}
}
@article{DBLP:journals/corr/abs-1709-00382,
  author       = {Guotai Wang and
                  Wenqi Li and
                  S{\'{e}}bastien Ourselin and
                  Tom Vercauteren},
  title        = {Automatic Brain Tumor Segmentation using Cascaded Anisotropic Convolutional
                  Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1709.00382},
  year         = {2017},
  url          = {http://arxiv.org/abs/1709.00382},
  eprinttype    = {arXiv},
  eprint       = {1709.00382},
  timestamp    = {Fri, 11 Feb 2022 16:53:28 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1709-00382.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{ZHANG2016150,
title = {Deep learning based classification of breast tumors with shear-wave elastography},
journal = {Ultrasonics},
volume = {72},
pages = {150-157},
year = {2016},
issn = {0041-624X},
doi = {https://doi.org/10.1016/j.ultras.2016.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0041624X16301378},
author = {Qi Zhang and Yang Xiao and Wei Dai and Jingfeng Suo and Congzhi Wang and Jun Shi and Hairong Zheng},
keywords = {Deep learning, Shear-wave elastography, Breast tumors, Point-wise gated Boltzmann machine, Computer-aided diagnosis},
abstract = {This study aims to build a deep learning (DL) architecture for automated extraction of learned-from-data image features from the shear-wave elastography (SWE), and to evaluate the DL architecture in differentiation between benign and malignant breast tumors. We construct a two-layer DL architecture for SWE feature extraction, comprised of the point-wise gated Boltzmann machine (PGBM) and the restricted Boltzmann machine (RBM). The PGBM contains task-relevant and task-irrelevant hidden units, and the task-relevant units are connected to the RBM. Experimental evaluation was performed with five-fold cross validation on a set of 227 SWE images, 135 of benign tumors and 92 of malignant tumors, from 121 patients. The features learned with our DL architecture were compared with the statistical features quantifying image intensity and texture. Results showed that the DL features achieved better classification performance with an accuracy of 93.4%, a sensitivity of 88.6%, a specificity of 97.1%, and an area under the receiver operating characteristic curve of 0.947. The DL-based method integrates feature learning with feature selection on SWE. It may be potentially used in clinical computer-aided diagnosis of breast cancer.}
}
@Article{Li2021x,
author="Li, Jianning
and Gsaxner, Christina
and Pepe, Antonio
and Morais, Ana
and Alves, Victor
and von Campe, Gord
and Wallner, J{\"u}rgen
and Egger, Jan",
title="Synthetic skull bone defects for automatic patient-specific craniofacial implant design",
journal="Scientific Data",
year="2021",
month="Jan",
day="29",
volume="8",
number="1",
pages="36",
abstract="Patient-specific craniofacial implants are used to repair skull bone defects after trauma or surgery. Currently, cranial implants are designed and produced by third-party suppliers, which is usually time-consuming and expensive. Recent advances in additive manufacturing made the in-hospital or in-operation-room fabrication of personalized implants feasible. However, the implants are still manufactured by external companies. To facilitate an optimized workflow, fast and automatic implant manufacturing is highly desirable. Data-driven approaches, such as deep learning, show currently great potential towards automatic implant design. However, a considerable amount of data is needed to train such algorithms, which is, especially in the medical domain, often a bottleneck. Therefore, we present CT-imaging data of the craniofacial complex from 24 patients, in which we injected various artificial cranial defects, resulting in 240 data pairs and 240 corresponding implants. Based on this work, automatic implant design and manufacturing processes can be trained. Additionally, the data of this work build a solid base for researchers to work on automatic cranial implant designs.",
issn="2052-4463",
doi="10.1038/s41597-021-00806-0",
url="https://doi.org/10.1038/s41597-021-00806-0"
}
@article{KODYM2021106902,
title = {SkullBreak / SkullFix – Dataset for automatic cranial implant design and a benchmark for volumetric shape learning tasks},
journal = {Data in Brief},
volume = {35},
pages = {106902},
year = {2021},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2021.106902},
url = {https://www.sciencedirect.com/science/article/pii/S2352340921001864},
author = {Oldřich Kodym and Jianning Li and Antonio Pepe and Christina Gsaxner and Sasank Chilamkurthy and Jan Egger and Michal Španěl},
keywords = {cranial implant design, cranioplasty, deep learning, volumetric shape learning, skull, autoimplant},
abstract = {The article introduces two complementary datasets intended for the development of data-driven solutions for cranial implant design, which remains to be a time-consuming and laborious task in current clinical routine of cranioplasty. The two datasets, referred to as the SkullBreak and SkullFix in this article, are both adapted from a public head CT collection CQ500 (http://headctstudy.qure.ai/dataset) with CC BY-NC-SA 4.0 license. The SkullBreak contains 114 and 20 complete skulls, each accompanied by five defective skulls and the corresponding cranial implants, for training and evaluation respectively. The SkullFix contains 100 triplets (complete skull, defective skull and the implant) for training and 110 triplets for evaluation. The SkullFix dataset was first used in the MICCAI 2020 AutoImplant Challenge (https://autoimplant.grand-challenge.org/) and the ground truth, i.e., the complete skulls and the implants in the evaluation set are held private by the organizers. The two datasets are not overlapping and differ regarding data selection and synthetic defect creation and each serves as a complement to the other. Besides cranial implant design, the datasets can be used for the evaluation of volumetric shape learning algorithms, such as volumetric shape completion. This article gives a description of the two datasets in detail.}
}
@article{ALDHABYANI2020104863,
title = {Dataset of breast ultrasound images},
journal = {Data in Brief},
volume = {28},
pages = {104863},
year = {2020},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2019.104863},
url = {https://www.sciencedirect.com/science/article/pii/S2352340919312181},
author = {Walid Al-Dhabyani and Mohammed Gomaa and Hussien Khaled and Aly Fahmy},
keywords = {Ultrasound, Breast cancer, Medical images, Dataset, Deep learning, Classification, Segmentation, Detection},
abstract = {Breast cancer is one of the most common causes of death among women worldwide. Early detection helps in reducing the number of early deaths. The data presented in this article reviews the medical images of breast cancer using ultrasound scan. Breast Ultrasound Dataset is categorized into three classes: normal, benign, and malignant images. Breast ultrasound images can produce great results in classification, detection, and segmentation of breast cancer when combined with machine learning.}
}
@inproceedings{10.1117/12.2588220,
author = {Yuan Jin and Antonio Pepe and Jianning Li and Christina Gsaxner and Jan Egger},
title = {{Deep learning and particle filter-based aortic dissection vessel tree segmentation}},
volume = {11600},
booktitle = {Medical Imaging 2021: Biomedical Applications in Molecular, Structural, and Functional Imaging},
editor = {Barjor S. Gimi and Andrzej Krol},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {116001W},
abstract = {Aortic dissections (AD) are injuries of the inner vessel wall of the (human) aorta. As this disease poses a significant threat to a patient’s life, it is crucial to observe and analyze the progression of the dissection over the course of the disease. The clinical examinations are usually performed with the application of Computed Tomography (CT) or Computed Tomography Angiography (CTA), based on which, automated post-processing procedures would be beneficial for the management of critical pathologies. One of the main tasks during post-processing is aorta segmentation. Different methods have been developed for the segmentation of aorta, including the tracking methods, the active contour/surface methods and the deep learning methods. In this study, a method for the automatic segmentation of aorta and its branches from original thorax CT and CTA images is introduced. The aorta is segmented based on deep learning algorithm and afterwards the branches are tracked based on particle filter algorithm.},
keywords = {Aortic Dissection, Computed Tomography Angiography, Segmentation, Deep Learning, V-Net, Particle Filter},
year = {2021},
doi = {10.1117/12.2588220},
URL = {https://doi.org/10.1117/12.2588220}
}
